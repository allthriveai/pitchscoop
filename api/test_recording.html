<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PitchScoop Recording Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .recording-section {
            text-align: center;
            margin: 30px 0;
        }
        .record-btn {
            background: #e74c3c;
            color: white;
            border: none;
            padding: 20px 40px;
            font-size: 18px;
            border-radius: 50px;
            cursor: pointer;
            margin: 10px;
            transition: all 0.3s;
        }
        .record-btn:hover {
            background: #c0392b;
            transform: scale(1.05);
        }
        .record-btn:disabled {
            background: #95a5a6;
            cursor: not-allowed;
            transform: none;
        }
        .recording {
            background: #e74c3c;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        .stop-btn {
            background: #2c3e50;
        }
        .stop-btn:hover {
            background: #34495e;
        }
        .status {
            margin: 20px 0;
            padding: 15px;
            border-radius: 5px;
            min-height: 20px;
        }
        .status.info {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .status.warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        .form-group {
            margin: 20px 0;
            text-align: left;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
            color: #333;
        }
        input[type="text"] {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 5px;
            font-size: 16px;
            box-sizing: border-box;
        }
        input[type="text"]:focus {
            border-color: #3498db;
            outline: none;
        }
        .results {
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 5px;
            border-left: 4px solid #3498db;
        }
        .audio-player {
            width: 100%;
            margin: 15px 0;
        }
        .playback-url {
            word-break: break-all;
            background: #e9ecef;
            padding: 10px;
            border-radius: 3px;
            font-family: monospace;
            font-size: 12px;
        }
        .timer {
            font-size: 24px;
            color: #e74c3c;
            margin: 10px 0;
            font-weight: bold;
        }
        .config-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 4px solid #17a2b8;
        }
        .config-section h3 {
            margin-top: 0;
            color: #17a2b8;
        }
        .checkbox-group {
            margin: 10px 0;
        }
        input[type="checkbox"] {
            margin-right: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ PitchScoop Recording Test</h1>
        
        <div class="config-section">
            <h3>Recording Configuration</h3>
            <div class="form-group">
                <label for="teamName">Team Name:</label>
                <input type="text" id="teamName" value="Test Team" placeholder="Enter team name">
            </div>
            <div class="form-group">
                <label for="pitchTitle">Pitch Title:</label>
                <input type="text" id="pitchTitle" value="Browser Recording Test" placeholder="Enter pitch title">
            </div>
            <div class="form-group">
                <label for="microphoneSelect">Microphone:</label>
                <select id="microphoneSelect" style="width: 100%; padding: 10px; border: 2px solid #ddd; border-radius: 5px; font-size: 16px;">
                    <option value="">üîÑ Loading microphones...</option>
                </select>
                <button id="refreshMics" type="button" style="margin-top: 5px; padding: 5px 10px; background: #17a2b8; color: white; border: none; border-radius: 3px; cursor: pointer;">üîÑ Refresh Microphones</button>
            </div>
            <div class="checkbox-group">
                <label>
                    <input type="checkbox" id="autoUpload" checked> Auto-upload after recording
                </label>
            </div>
            <div class="checkbox-group">
                <label>
                    <input type="checkbox" id="showAdvanced"> Show advanced options
                </label>
            </div>
            <div class="checkbox-group">
                <button id="testMicBtn" type="button" style="padding: 10px 15px; background: #f39c12; color: white; border: none; border-radius: 5px; cursor: pointer; margin-top: 10px;">üß™ Test Selected Microphone</button>
            </div>
        </div>

        <div class="recording-section">
            <div class="timer" id="timer">00:00</div>
            <div id="audioLevelContainer" style="margin: 15px 0; display: none;">
                <label>Audio Level:</label>
                <div style="background: #ddd; height: 10px; border-radius: 5px; overflow: hidden; margin: 5px 0;">
                    <div id="audioLevelBar" style="background: #27ae60; height: 100%; width: 0%; transition: width 0.1s;"></div>
                </div>
                <small id="audioLevelText">0%</small>
            </div>
            <button id="startBtn" class="record-btn">üî¥ Start Recording</button>
            <button id="stopBtn" class="record-btn stop-btn" disabled>‚èπÔ∏è Stop Recording</button>
            <button id="uploadBtn" class="record-btn stop-btn" disabled>üì§ Upload to PitchScoop</button>
        </div>

        <div id="status" class="status info">
            Ready to record. Click "Start Recording" to begin.
        </div>

        <div id="results" class="results" style="display:none;">
            <h3>üìä Recording Results</h3>
            <div id="sessionInfo"></div>
            <div id="audioPlayer"></div>
            <div id="playbackUrl"></div>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let recordedChunks = [];
        let stream;
        let startTime;
        let timerInterval;
        let recordedBlob;
        let availableDevices = [];
        let selectedDeviceId = null;
        let audioContext;
        let analyser;
        let microphone;
        let levelMonitoringActive = false;
        
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const uploadBtn = document.getElementById('uploadBtn');
        const status = document.getElementById('status');
        const results = document.getElementById('results');
        const timer = document.getElementById('timer');
        const microphoneSelect = document.getElementById('microphoneSelect');
        const refreshMicsBtn = document.getElementById('refreshMics');
        const testMicBtn = document.getElementById('testMicBtn');
        
        // API endpoint - using the simple test server
        const API_BASE_URL = 'http://localhost:8000';
        
        // Microphone enumeration and selection functions
        async function enumerateAudioDevices() {
            try {
                updateStatus('Detecting available microphones...', 'warning');
                
                // First, enumerate devices without permissions (limited info)
                let devices = await navigator.mediaDevices.enumerateDevices();
                let audioInputs = devices.filter(device => device.kind === 'audioinput');
                
                console.log('üé§ Initial device detection:', audioInputs);
                
                // If we don't have device labels, we need to request permission
                const needsPermission = audioInputs.some(device => !device.label);
                
                if (needsPermission) {
                    console.log('üé§ Requesting microphone permissions...');
                    updateStatus('Requesting microphone permissions to identify devices...', 'warning');
                    
                    // Try different permission strategies
                    let permissionStream = null;
                    
                    try {
                        // Method 1: Request general audio permission
                        permissionStream = await navigator.mediaDevices.getUserMedia({ 
                            audio: {
                                echoCancellation: false,
                                noiseSuppression: false,
                                autoGainControl: false
                            } 
                        });
                    } catch (generalError) {
                        console.warn('üé§ General permission failed:', generalError.message);
                        
                        try {
                            // Method 2: Request basic audio permission
                            permissionStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        } catch (basicError) {
                            console.error('üé§ All permission requests failed:', basicError.message);
                            throw basicError;
                        }
                    }
                    
                    if (permissionStream) {
                        console.log('üé§ Permission stream obtained:', permissionStream.getAudioTracks().map(track => ({
                            label: track.label,
                            deviceId: track.getSettings().deviceId,
                            settings: track.getSettings()
                        })));
                        
                        permissionStream.getTracks().forEach(track => track.stop());
                    }
                    
                    // Re-enumerate with permissions
                    devices = await navigator.mediaDevices.enumerateDevices();
                    audioInputs = devices.filter(device => device.kind === 'audioinput');
                }
                
                availableDevices = audioInputs;
                console.log('üé§ Final available devices:', availableDevices);
                
                updateMicrophoneDropdown();
                
            } catch (error) {
                console.error('Error enumerating audio devices:', error);
                updateStatus(`Failed to access microphones: ${error.message}. Please check browser permissions.`, 'error');
                
                // Show basic troubleshooting info
                setTimeout(() => {
                    const troubleshoot = `
                    üé§ MICROPHONE TROUBLESHOOTING:
                    1. Check that your browser has microphone permissions
                    2. Make sure your external microphone is properly connected
                    3. Try refreshing the page and granting permissions again
                    4. Check if other apps are using the microphone
                    5. Try using Chrome/Edge instead of Safari if on Mac
                    `;
                    console.log(troubleshoot);
                }, 1000);
            }
        }
        
        function updateMicrophoneDropdown() {
            microphoneSelect.innerHTML = '';
            
            if (availableDevices.length === 0) {
                microphoneSelect.innerHTML = '<option value="">‚ùå No microphones found</option>';
                return;
            }
            
            // Add default option
            const defaultOption = document.createElement('option');
            defaultOption.value = '';
            defaultOption.textContent = 'üé§ Select a microphone...';
            microphoneSelect.appendChild(defaultOption);
            
            // Add each available microphone
            availableDevices.forEach((device, index) => {
                const option = document.createElement('option');
                option.value = device.deviceId;
                
                // Create a descriptive label
                let label = device.label || `Microphone ${index + 1}`;
                
                // Add device type hints based on label
                if (label.toLowerCase().includes('built-in') || label.toLowerCase().includes('internal')) {
                    label = `üíª ${label} (Built-in)`;
                } else if (label.toLowerCase().includes('usb')) {
                    label = `üîå ${label} (USB)`;
                } else if (label.toLowerCase().includes('bluetooth') || label.toLowerCase().includes('airpods') || label.toLowerCase().includes('headset')) {
                    label = `üì± ${label} (Bluetooth/Phone)`;
                } else {
                    label = `üé§ ${label}`;
                }
                
                option.textContent = label;
                microphoneSelect.appendChild(option);
                
                // Auto-select first non-phone/bluetooth device
                if (!selectedDeviceId && !label.includes('Phone') && !label.includes('Bluetooth') && !label.includes('AirPods')) {
                    selectedDeviceId = device.deviceId;
                    option.selected = true;
                }
            });
            
            updateStatus(`Found ${availableDevices.length} microphone(s). Please select your preferred microphone.`, 'info');
        }
        
        function onMicrophoneChange() {
            selectedDeviceId = microphoneSelect.value;
            const selectedDevice = availableDevices.find(d => d.deviceId === selectedDeviceId);
            
            if (selectedDevice) {
                updateStatus(`Selected: ${selectedDevice.label || 'Microphone'}`, 'info');
            } else {
                updateStatus('Please select a microphone before recording.', 'warning');
            }
        }
        
        function startAudioLevelMonitoring(stream) {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                microphone.connect(analyser);
                levelMonitoringActive = true;
                
                document.getElementById('audioLevelContainer').style.display = 'block';
                
                function updateLevel() {
                    if (!levelMonitoringActive) return;
                    
                    analyser.getByteFrequencyData(dataArray);
                    
                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    const percentage = Math.round((average / 255) * 100);
                    
                    // Update visual indicator
                    const levelBar = document.getElementById('audioLevelBar');
                    const levelText = document.getElementById('audioLevelText');
                    
                    levelBar.style.width = `${percentage}%`;
                    levelText.textContent = `${percentage}%`;
                    
                    // Color coding based on level
                    if (percentage < 10) {
                        levelBar.style.background = '#e74c3c'; // Red - too quiet
                    } else if (percentage < 30) {
                        levelBar.style.background = '#f39c12'; // Orange - low
                    } else if (percentage < 80) {
                        levelBar.style.background = '#27ae60'; // Green - good
                    } else {
                        levelBar.style.background = '#e74c3c'; // Red - too loud
                    }
                    
                    requestAnimationFrame(updateLevel);
                }
                
                updateLevel();
                
            } catch (error) {
                console.error('Error starting audio level monitoring:', error);
            }
        }
        
        function stopAudioLevelMonitoring() {
            levelMonitoringActive = false;
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            document.getElementById('audioLevelContainer').style.display = 'none';
            document.getElementById('audioLevelBar').style.width = '0%';
            document.getElementById('audioLevelText').textContent = '0%';
        }
        
        // Test microphone function
        async function testSelectedMicrophone() {
            if (!selectedDeviceId) {
                updateStatus('Please select a microphone first!', 'error');
                return;
            }
            
            const selectedDevice = availableDevices.find(d => d.deviceId === selectedDeviceId);
            updateStatus(`Testing microphone: ${selectedDevice?.label || 'Selected microphone'}...`, 'warning');
            
            console.log('üß™ Testing microphone:', selectedDevice);
            
            let testStream = null;
            
            try {
                // Test multiple constraint configurations
                const testConstraints = [
                    // Test 1: Basic access
                    { deviceId: { ideal: selectedDeviceId } },
                    // Test 2: With sample rate
                    { deviceId: { ideal: selectedDeviceId }, sampleRate: { ideal: 16000 } },
                    // Test 3: With processing
                    { 
                        deviceId: { ideal: selectedDeviceId }, 
                        echoCancellation: true, 
                        noiseSuppression: true 
                    },
                    // Test 4: Exact device ID
                    { deviceId: { exact: selectedDeviceId } }
                ];
                
                for (let i = 0; i < testConstraints.length; i++) {
                    const constraints = testConstraints[i];
                    
                    try {
                        console.log(`üß™ Test ${i + 1} - Constraints:`, constraints);
                        
                        testStream = await navigator.mediaDevices.getUserMedia({ audio: constraints });
                        
                        const track = testStream.getAudioTracks()[0];
                        const settings = track.getSettings();
                        const capabilities = track.getCapabilities ? track.getCapabilities() : {};
                        
                        console.log(`üß™ Test ${i + 1} - SUCCESS`);
                        console.log('üß™ Track settings:', settings);
                        console.log('üß™ Track capabilities:', capabilities);
                        console.log('üß™ Track label:', track.label);
                        console.log('üß™ Track kind:', track.kind);
                        console.log('üß™ Track enabled:', track.enabled);
                        console.log('üß™ Track muted:', track.muted);
                        console.log('üß™ Track readyState:', track.readyState);
                        
                        // Quick audio level test
                        const testAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                        const testAnalyser = testAudioContext.createAnalyser();
                        const testMicrophone = testAudioContext.createMediaStreamSource(testStream);
                        testMicrophone.connect(testAnalyser);
                        
                        testAnalyser.fftSize = 256;
                        const testDataArray = new Uint8Array(testAnalyser.frequencyBinCount);
                        
                        setTimeout(() => {
                            testAnalyser.getByteFrequencyData(testDataArray);
                            let sum = 0;
                            for (let j = 0; j < testDataArray.length; j++) {
                                sum += testDataArray[j];
                            }
                            const average = sum / testDataArray.length;
                            const percentage = Math.round((average / 255) * 100);
                            
                            console.log(`üß™ Audio level test: ${percentage}% (${average}/255)`);
                            console.log('üß™ Raw frequency data sample:', testDataArray.slice(0, 10));
                            
                            testAudioContext.close();
                            
                            if (percentage > 0) {
                                updateStatus(`‚úÖ Microphone test PASSED! Audio detected (${percentage}% level). Constraint set ${i + 1} works.`, 'info');
                            } else {
                                updateStatus(`‚ö†Ô∏è Microphone accessible but no audio detected. Speak into the microphone or check volume levels.`, 'warning');
                            }
                        }, 2000);
                        
                        // Stop test stream
                        setTimeout(() => {
                            testStream.getTracks().forEach(track => track.stop());
                        }, 3000);
                        
                        return; // Exit on first successful test
                        
                    } catch (testError) {
                        console.log(`üß™ Test ${i + 1} - FAILED:`, testError.message);
                        
                        if (testStream) {
                            testStream.getTracks().forEach(track => track.stop());
                            testStream = null;
                        }
                    }
                }
                
                // If we get here, all tests failed
                throw new Error('All microphone test configurations failed');
                
            } catch (error) {
                console.error('üß™ Microphone test failed:', error);
                updateStatus(`‚ùå Microphone test FAILED: ${error.message}`, 'error');
                
                // Cleanup
                if (testStream) {
                    testStream.getTracks().forEach(track => track.stop());
                }
            }
        }
        
        function updateStatus(message, type = 'info') {
            status.textContent = message;
            status.className = `status ${type}`;
        }
        
        function updateTimer() {
            if (!startTime) return;
            const elapsed = Date.now() - startTime;
            const minutes = Math.floor(elapsed / 60000);
            const seconds = Math.floor((elapsed % 60000) / 1000);
            timer.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
        }
        
        async function startRecording() {
            try {
                // Check if microphone is selected
                if (!selectedDeviceId) {
                    updateStatus('Please select a microphone first!', 'error');
                    return;
                }
                
                // Request microphone access with selected device
                const selectedDevice = availableDevices.find(d => d.deviceId === selectedDeviceId);
                updateStatus(`Starting recording with: ${selectedDevice?.label || 'Selected microphone'}...`, 'warning');
                
                console.log('üé§ Selected device:', selectedDevice);
                console.log('üé§ Device ID:', selectedDeviceId);
                
                // Try multiple constraint configurations for better compatibility
                const constraintOptions = [
                    // Option 1: Strict constraints (current approach)
                    {
                        deviceId: { exact: selectedDeviceId },
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    },
                    // Option 2: More flexible constraints
                    {
                        deviceId: { ideal: selectedDeviceId },
                        sampleRate: { ideal: 16000 },
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    },
                    // Option 3: Basic constraints (most compatible)
                    {
                        deviceId: { ideal: selectedDeviceId },
                        echoCancellation: false,
                        noiseSuppression: false
                    },
                    // Option 4: Minimal constraints
                    {
                        deviceId: { ideal: selectedDeviceId }
                    }
                ];
                
                stream = null; // Use global stream variable
                let usedConstraints = null;
                
                // Try each constraint configuration until one works
                for (let i = 0; i < constraintOptions.length; i++) {
                    try {
                        console.log(`üé§ Trying constraint option ${i + 1}:`, constraintOptions[i]);
                        
                        stream = await navigator.mediaDevices.getUserMedia({
                            audio: constraintOptions[i]
                        });
                        
                        usedConstraints = constraintOptions[i];
                        console.log(`üé§ Success with constraint option ${i + 1}`);
                        break;
                        
                    } catch (constraintError) {
                        console.warn(`üé§ Constraint option ${i + 1} failed:`, constraintError.message);
                        
                        if (i === constraintOptions.length - 1) {
                            // If all constraints fail, throw the last error
                            throw constraintError;
                        }
                    }
                }
                
                if (!stream) {
                    throw new Error('Could not access microphone with any constraint configuration');
                }
                
                // Log the actual stream settings
                const audioTracks = stream.getAudioTracks();
                if (audioTracks.length > 0) {
                    const track = audioTracks[0];
                    console.log('üé§ Actual stream settings:', track.getSettings());
                    console.log('üé§ Stream constraints used:', usedConstraints);
                    
                    updateStatus(`üé§ Recording started with ${track.label || 'microphone'} (${JSON.stringify(track.getSettings())})`, 'info');
                }
                
                // Start audio level monitoring
                startAudioLevelMonitoring(stream);
                
                // Test microphone functionality
                const testRecordingCapability = () => {
                    const audioTracks = stream.getAudioTracks();
                    if (audioTracks.length > 0) {
                        const track = audioTracks[0];
                        const capabilities = track.getCapabilities ? track.getCapabilities() : {};
                        console.log('üé§ Microphone capabilities:', capabilities);
                        
                        // Check if the track is actually getting audio data
                        setTimeout(() => {
                            const settings = track.getSettings();
                            console.log('üé§ Current microphone settings:', settings);
                            
                            if (settings.deviceId !== selectedDeviceId) {
                                console.warn('üé§ Warning: Using different device than selected!');
                                console.warn('üé§ Selected:', selectedDeviceId);
                                console.warn('üé§ Actual:', settings.deviceId);
                            }
                        }, 1000);
                    }
                };
                
                testRecordingCapability();
                
                recordedChunks = [];
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    recordedBlob = new Blob(recordedChunks, { type: 'audio/webm' });
                    clearInterval(timerInterval);
                    
                    // Create local audio player
                    const audioURL = URL.createObjectURL(recordedBlob);
                    const audioPlayer = document.getElementById('audioPlayer');
                    audioPlayer.innerHTML = `
                        <h4>üéµ Recorded Audio (${Math.round(recordedBlob.size / 1024)}KB)</h4>
                        <audio controls class="audio-player">
                            <source src="${audioURL}" type="audio/webm">
                            Your browser does not support the audio element.
                        </audio>
                    `;
                    
                    updateStatus('Recording completed! You can play it back or upload to PitchScoop.', 'info');
                    uploadBtn.disabled = false;
                    
                    // Auto-upload if enabled
                    if (document.getElementById('autoUpload').checked) {
                        await uploadRecording();
                    }
                };
                
                // Start recording
                mediaRecorder.start(100); // Record in 100ms chunks
                startTime = Date.now();
                timerInterval = setInterval(updateTimer, 100);
                
                startBtn.disabled = true;
                startBtn.className = 'record-btn recording';
                stopBtn.disabled = false;
                
                updateStatus('üî¥ Recording... Speak into your microphone!', 'info');
                
            } catch (error) {
                updateStatus(`Failed to start recording: ${error.message}`, 'error');
                console.error('Recording error:', error);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                
                // Safely stop stream tracks
                if (stream && stream.getTracks) {
                    stream.getTracks().forEach(track => track.stop());
                }
                
                // Stop audio level monitoring
                stopAudioLevelMonitoring();
                
                startBtn.disabled = false;
                startBtn.className = 'record-btn';
                stopBtn.disabled = true;
                
                results.style.display = 'block';
            }
        }
        
        async function uploadRecording() {
            if (!recordedBlob) {
                updateStatus('No recording to upload!', 'error');
                return;
            }
            
            try {
                updateStatus('Uploading to PitchScoop...', 'warning');
                uploadBtn.disabled = true;
                
                const teamName = document.getElementById('teamName').value || 'Test Team';
                const pitchTitle = document.getElementById('pitchTitle').value || 'Browser Recording Test';
                
                // Step 1: Create an event
                updateStatus('Creating event...', 'warning');
                const eventResponse = await fetch(`${API_BASE_URL}/mcp/execute`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        tool: 'events.create_event',
                        arguments: {
                            event_type: 'individual_practice',
                            event_name: 'Browser Recording Test Event',
                            description: 'Test event created from browser recording',
                            max_participants: 1,
                            duration_minutes: 10
                        }
                    })
                });
                
                const eventData = await eventResponse.json();
                if (eventData.error) {
                    throw new Error(`Event creation failed: ${eventData.error}`);
                }
                
                const eventId = eventData.event_id;
                updateStatus(`Event created: ${eventId}`, 'info');
                
                // Step 2: Start recording session
                updateStatus('Starting recording session...', 'warning');
                const sessionResponse = await fetch(`${API_BASE_URL}/mcp/execute`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        tool: 'pitches.start_recording',
                        arguments: {
                            event_id: eventId,
                            team_name: teamName,
                            pitch_title: pitchTitle
                        }
                    })
                });
                
                const sessionData = await sessionResponse.json();
                if (sessionData.error) {
                    throw new Error(`Session creation failed: ${sessionData.error}`);
                }
                
                const sessionId = sessionData.session_id;
                updateStatus(`Recording session created: ${sessionId}`, 'info');
                
                // Step 3: Convert audio to WAV and base64 encode
                updateStatus('Converting audio to WAV format...', 'warning');
                
                // Create an audio context to convert to WAV
                const audioContext = new AudioContext();
                const arrayBuffer = await recordedBlob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // Convert to WAV
                const wavBlob = audioBufferToWav(audioBuffer);
                const reader = new FileReader();
                
                reader.onload = async () => {
                    const base64Audio = reader.result.split(',')[1]; // Remove data:audio/wav;base64, prefix
                    
                    // Step 4: Stop recording with audio data
                    updateStatus('Uploading audio to MinIO...', 'warning');
                    const stopResponse = await fetch(`${API_BASE_URL}/mcp/execute`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            tool: 'pitches.stop_recording',
                            arguments: {
                                session_id: sessionId,
                                audio_data_base64: base64Audio
                            }
                        })
                    });
                    
                    const stopData = await stopResponse.json();
                    if (stopData.error) {
                        throw new Error(`Upload failed: ${stopData.error}`);
                    }
                    
                    // Step 5: Get playback URL
                    updateStatus('Generating playback URL...', 'warning');
                    const playbackResponse = await fetch(`${API_BASE_URL}/mcp/execute`, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify({
                            tool: 'pitches.get_playback_url',
                            arguments: {
                                session_id: sessionId,
                                expires_hours: 24
                            }
                        })
                    });
                    
                    const playbackData = await playbackResponse.json();
                    
                    // Display results
                    const sessionInfo = document.getElementById('sessionInfo');
                    
                    // Check for transcript
                    let transcriptHtml = '';
                    const transcript = stopData.transcript;
                    if (transcript) {
                        const totalText = transcript.total_text || '';
                        const segmentCount = transcript.segments_count || 0;
                        const segments = transcript.segments || [];
                        
                        if (totalText.trim()) {
                            // Calculate average confidence
                            let avgConfidence = 0;
                            let confidenceCount = 0;
                            let qualityWarning = '';
                            
                            segments.forEach(seg => {
                                if (seg.confidence !== undefined) {
                                    avgConfidence += seg.confidence;
                                    confidenceCount++;
                                }
                            });
                            
                            if (confidenceCount > 0) {
                                avgConfidence = avgConfidence / confidenceCount;
                                
                                if (avgConfidence < 0.3) {
                                    qualityWarning = '<div style="background: #f8d7da; color: #721c24; padding: 10px; border-radius: 5px; margin: 10px 0;">‚ö†Ô∏è <strong>Very Low Quality:</strong> Transcript may be inaccurate. Try speaking louder and closer to the microphone.</div>';
                                } else if (avgConfidence < 0.6) {
                                    qualityWarning = '<div style="background: #fff3cd; color: #856404; padding: 10px; border-radius: 5px; margin: 10px 0;">‚ö†Ô∏è <strong>Low Quality:</strong> Consider improving audio quality for better accuracy.</div>';
                                } else {
                                    qualityWarning = '<div style="background: #d4edda; color: #155724; padding: 10px; border-radius: 5px; margin: 10px 0;">‚úÖ <strong>Good Quality:</strong> Transcript should be accurate.</div>';
                                }
                            }
                            
                            let segmentDetails = '';
                            if (segments.length > 0) {
                                segmentDetails = '<h5>Segment Details:</h5>';
                                segments.forEach((seg, i) => {
                                    const conf = seg.confidence !== undefined ? (seg.confidence * 100).toFixed(0) + '%' : 'N/A';
                                    const confColor = seg.confidence < 0.3 ? '#e74c3c' : seg.confidence < 0.6 ? '#f39c12' : '#27ae60';
                                    segmentDetails += `<div style="margin: 5px 0; padding: 8px; background: #f8f9fa; border-radius: 3px;"><strong>"${seg.text}"</strong> <span style="color: ${confColor}; font-weight: bold;">(${conf})</span></div>`;
                                });
                            }
                            
                            transcriptHtml = `
                                <h4>üìù Transcript</h4>
                                <div style="background: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;">
                                    <strong>"${totalText}"</strong>
                                </div>
                                ${qualityWarning}
                                <p><small>Segments: ${segmentCount} | Avg. Confidence: ${confidenceCount > 0 ? (avgConfidence * 100).toFixed(0) + '%' : 'N/A'}</small></p>
                                ${segmentDetails}
                            `;
                        } else if (segmentCount > 0) {
                            transcriptHtml = `
                                <h4>üìù Transcript</h4>
                                <p><em>Processing completed but no text detected (${segmentCount} segments processed)</em></p>
                            `;
                        } else {
                            transcriptHtml = `
                                <h4>üìù Transcript</h4>
                                <p><em>No transcript segments detected - this may happen with synthetic audio or background noise</em></p>
                            `;
                        }
                    }
                    
                    // Debug: Log the full response for analysis
                    console.log('üîç Full stopData response:', stopData);
                    console.log('üîç Transcript object:', transcript);
                    if (transcript && transcript.segments) {
                        console.log('üîç Individual segments:', transcript.segments);
                    }
                    
                    sessionInfo.innerHTML = `
                        <h4>‚úÖ Upload Successful!</h4>
                        <p><strong>Session ID:</strong> ${sessionId}</p>
                        <p><strong>Event ID:</strong> ${eventId}</p>
                        <p><strong>Team:</strong> ${teamName}</p>
                        <p><strong>Title:</strong> ${pitchTitle}</p>
                        <p><strong>Status:</strong> ${stopData.status}</p>
                        <p><strong>File Size:</strong> ${Math.round(wavBlob.size / 1024)}KB (WAV format)</p>
                        <p><strong>Processing Method:</strong> ${transcript && transcript.audio_intelligence && Object.keys(transcript.audio_intelligence).length > 0 ? 'Batch API (Audio Intelligence)' : 'WebSocket API (Basic)'}</p>
                        ${transcriptHtml}
                    `;
                    
                    // Display playback URL - check both stopData and playbackData
                    const playbackUrl = document.getElementById('playbackUrl');
                    let audioUrl = null;
                    
                    // First try to get URL from stopData (more reliable)
                    if (stopData.audio && stopData.audio.playback_url) {
                        audioUrl = stopData.audio.playback_url;
                    } else if (playbackData && playbackData.playback_url) {
                        audioUrl = playbackData.playback_url;
                    }
                    
                    if (audioUrl) {
                        playbackUrl.innerHTML = `
                            <h4>üîó MinIO Playback URL:</h4>
                            <div class="playback-url">${audioUrl}</div>
                            <p><small>This URL expires in 24 hours</small></p>
                            <audio controls class="audio-player">
                                <source src="${audioUrl}" type="audio/wav">
                                Your browser does not support the audio element.
                            </audio>
                        `;
                    } else {
                        playbackUrl.innerHTML = '<p>‚ö†Ô∏è No playback URL available</p>';
                    }
                    
                    updateStatus('üéâ Recording successfully uploaded to MinIO!', 'info');
                };
                
                reader.readAsDataURL(wavBlob);
                
            } catch (error) {
                updateStatus(`Upload failed: ${error.message}`, 'error');
                console.error('Upload error:', error);
                uploadBtn.disabled = false;
            }
        }
        
        // Convert AudioBuffer to WAV Blob
        function audioBufferToWav(buffer) {
            const length = buffer.length;
            const sampleRate = buffer.sampleRate;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            const channelData = buffer.getChannelData(0);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
            
            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }
        
        // Event listeners
        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        uploadBtn.addEventListener('click', uploadRecording);
        microphoneSelect.addEventListener('change', onMicrophoneChange);
        refreshMicsBtn.addEventListener('click', enumerateAudioDevices);
        testMicBtn.addEventListener('click', testSelectedMicrophone);
        
        // Initialize on page load
        window.addEventListener('load', async () => {
            // Check if browser supports recording
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                updateStatus('Your browser does not support audio recording!', 'error');
                startBtn.disabled = true;
                return;
            }
            
            // Enumerate available microphones
            await enumerateAudioDevices();
        });
    </script>
</body>
</html>