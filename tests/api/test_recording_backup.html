<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>PitchScoop Recording Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 30px;
        }
        .recording-section {
            text-align: center;
            margin: 30px 0;
        }
        .record-btn {
            background: #e74c3c;
            color: white;
            border: none;
            padding: 20px 40px;
            font-size: 18px;
            border-radius: 50px;
            cursor: pointer;
            margin: 10px;
            transition: all 0.3s;
        }
        .record-btn:hover {
            background: #c0392b;
            transform: scale(1.05);
        }
        .record-btn:disabled {
            background: #95a5a6;
            cursor: not-allowed;
            transform: none;
        }
        .recording {
            background: #e74c3c;
            animation: pulse 1s infinite;
        }
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        .stop-btn {
            background: #2c3e50;
        }
        .stop-btn:hover {
            background: #34495e;
        }
        .status {
            margin: 20px 0;
            padding: 15px;
            border-radius: 5px;
            min-height: 20px;
        }
        .status.info {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        .status.warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        .form-group {
            margin: 20px 0;
            text-align: left;
        }
        label {
            display: block;
            margin-bottom: 5px;
            font-weight: bold;
            color: #333;
        }
        input[type="text"] {
            width: 100%;
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 5px;
            font-size: 16px;
            box-sizing: border-box;
        }
        input[type="text"]:focus {
            border-color: #3498db;
            outline: none;
        }
        .results {
            margin: 30px 0;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 5px;
            border-left: 4px solid #3498db;
        }
        .audio-player {
            width: 100%;
            margin: 15px 0;
        }
        .playback-url {
            word-break: break-all;
            background: #e9ecef;
            padding: 10px;
            border-radius: 3px;
            font-family: monospace;
            font-size: 12px;
        }
        .timer {
            font-size: 24px;
            color: #e74c3c;
            margin: 10px 0;
            font-weight: bold;
        }
        .config-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            margin: 20px 0;
            border-left: 4px solid #17a2b8;
        }
        .config-section h3 {
            margin-top: 0;
            color: #17a2b8;
        }
        .checkbox-group {
            margin: 10px 0;
        }
        input[type="checkbox"] {
            margin-right: 10px;
        }
        
        /* Scoring Section Styles */
        .scoring-section {
            margin-top: 30px;
            border-top: 2px solid #3498db;
            padding-top: 30px;
        }
        .scoring-section h2 {
            color: #3498db;
            text-align: center;
            font-size: 1.8em;
            margin-bottom: 20px;
        }
        .session-list {
            display: grid;
            gap: 15px;
            margin-top: 15px;
        }
        .session-item {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .session-info {
            flex: 1;
        }
        .session-info h3 {
            margin: 0 0 5px 0;
            color: #333;
            font-size: 1.1em;
        }
        .session-info p {
            margin: 2px 0;
            color: #666;
            font-size: 0.9em;
        }
        .actions {
            display: flex;
            gap: 10px;
            flex-wrap: wrap;
        }
        .score-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 10px;
            padding: 25px;
            margin: 20px 0;
            text-align: center;
        }
        .score-display {
            font-size: 3em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        .grade-display {
            font-size: 2em;
            opacity: 0.9;
        }
        .metrics-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .metric-card {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
        }
        .metric-card h3 {
            margin: 0 0 15px 0;
            color: #333;
            font-size: 1.2em;
        }
        .coaching-insights {
            background: #e3f2fd;
            border-left: 4px solid #2196f3;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
        }
        .coaching-insights h3 {
            margin: 0 0 15px 0;
            color: #1976d2;
        }
        .coaching-insights ul {
            margin: 0;
            padding-left: 20px;
        }
        .coaching-insights li {
            margin: 8px 0;
            color: #333;
        }
        .status-badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 12px;
            font-weight: 500;
            text-transform: uppercase;
            margin-left: 10px;
        }
        .status-completed { background: #d1e7dd; color: #0a3622; }
        .status-ready { background: #cff4fc; color: #055160; }
        .status-error { background: #f8d7da; color: #721c24; }
        .analysis-metadata {
            background: #f8f9fa;
            border-radius: 6px;
            padding: 15px;
            margin-top: 20px;
            font-size: 0.9em;
            color: #666;
        }
        .scoring-btn {
            background: #17a2b8;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 12px;
            margin: 2px;
        }
        .scoring-btn:hover {
            background: #138496;
        }
        .scoring-btn.primary {
            background: #007bff;
        }
        .scoring-btn.primary:hover {
            background: #0056b3;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ PitchScoop Recording Test</h1>
        
        <div class="config-section">
            <h3>Recording Configuration</h3>
            <div class="form-group">
                <label for="teamName">Team Name:</label>
                <input type="text" id="teamName" value="Test Team" placeholder="Enter team name">
            </div>
            <div class="form-group">
                <label for="pitchTitle">Pitch Title:</label>
                <input type="text" id="pitchTitle" value="Browser Recording Test" placeholder="Enter pitch title">
            </div>
            <div class="form-group">
                <label for="microphoneSelect">Microphone:</label>
                <select id="microphoneSelect" style="width: 100%; padding: 10px; border: 2px solid #ddd; border-radius: 5px; font-size: 16px;">
                    <option value="">üîÑ Loading microphones...</option>
                </select>
                <button id="refreshMics" type="button" style="margin-top: 5px; padding: 5px 10px; background: #17a2b8; color: white; border: none; border-radius: 3px; cursor: pointer;">üîÑ Refresh Microphones</button>
            </div>
            <div class="checkbox-group">
                <label>
                    <input type="checkbox" id="showAdvanced"> Show advanced options
                </label>
            </div>
            <div class="checkbox-group">
                <button id="testMicBtn" type="button" style="padding: 10px 15px; background: #f39c12; color: white; border: none; border-radius: 5px; cursor: pointer; margin-top: 10px;">üß™ Test Selected Microphone</button>
            </div>
        </div>

        <div class="recording-section">
            <div class="timer" id="timer">00:00</div>
            <div id="audioLevelContainer" style="margin: 15px 0; display: none;">
                <label>Audio Level:</label>
                <div style="background: #ddd; height: 10px; border-radius: 5px; overflow: hidden; margin: 5px 0;">
                    <div id="audioLevelBar" style="background: #27ae60; height: 100%; width: 0%; transition: width 0.1s;"></div>
                </div>
                <small id="audioLevelText">0%</small>
            </div>
            <button id="startBtn" class="record-btn">üî¥ Start Recording</button>
            <button id="stopBtn" class="record-btn stop-btn" disabled>‚èπÔ∏è Stop Recording</button>
        </div>

        <div id="status" class="status info">
            Ready to record. Click "Start Recording" to begin.
        </div>

        <div id="results" class="results" style="display:none;">
            <h3>üìä Recording Results</h3>
            <div id="sessionInfo"></div>
            <div id="audioPlayer"></div>
        </div>
        
        <!-- Scoring Section -->
        <div class="scoring-section">
            <h2>üéØ Presentation Scoring</h2>
            <button onclick="loadSessions()" class="record-btn" style="background: #28a745; margin-bottom: 20px;">üîÑ Load Sessions</button>
            <div id="sessionsContainer">
                <div class="status info">Click "Load Sessions" to view completed recordings and get scores.</div>
            </div>
        </div>
        
        <!-- Scoring Results Section -->
        <div id="scoringResults" class="results" style="display: none;">
            <h3>üìà Presentation Analysis Results</h3>
            <div id="scoringContent"></div>
            <button onclick="hideScoringResults()" class="record-btn" style="background: #6c757d;">Close Results</button>
        </div>
    </div>

    <script>
        let mediaRecorder;
        let recordedChunks = [];
        let stream;
        let startTime;
        let timerInterval;
        let recordedBlob;
        let availableDevices = [];
        let selectedDeviceId = null;
        let audioContext;
        let analyser;
        let microphone;
        let levelMonitoringActive = false;
        
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const status = document.getElementById('status');
        const results = document.getElementById('results');
        const timer = document.getElementById('timer');
        const microphoneSelect = document.getElementById('microphoneSelect');
        const refreshMicsBtn = document.getElementById('refreshMics');
        const testMicBtn = document.getElementById('testMicBtn');
        
        // API endpoint - using the simple test server
        const API_BASE_URL = 'http://localhost:8000';
        
        // Microphone enumeration and selection functions
        async function enumerateAudioDevices() {
            try {
                updateStatus('Detecting available microphones...', 'warning');
                
                // First, enumerate devices without permissions (limited info)
                let devices = await navigator.mediaDevices.enumerateDevices();
                let audioInputs = devices.filter(device => device.kind === 'audioinput');
                
                console.log('üé§ Initial device detection:', audioInputs);
                
                // If we don't have device labels, we need to request permission
                const needsPermission = audioInputs.some(device => !device.label);
                
                if (needsPermission) {
                    console.log('üé§ Requesting microphone permissions...');
                    updateStatus('Requesting microphone permissions to identify devices...', 'warning');
                    
                    // Try different permission strategies
                    let permissionStream = null;
                    
                    try {
                        // Method 1: Request general audio permission
                        permissionStream = await navigator.mediaDevices.getUserMedia({ 
                            audio: {
                                echoCancellation: false,
                                noiseSuppression: false,
                                autoGainControl: false
                            } 
                        });
                    } catch (generalError) {
                        console.warn('üé§ General permission failed:', generalError.message);
                        
                        try {
                            // Method 2: Request basic audio permission
                            permissionStream = await navigator.mediaDevices.getUserMedia({ audio: true });
                        } catch (basicError) {
                            console.error('üé§ All permission requests failed:', basicError.message);
                            throw basicError;
                        }
                    }
                    
                    if (permissionStream) {
                        console.log('üé§ Permission stream obtained:', permissionStream.getAudioTracks().map(track => ({
                            label: track.label,
                            deviceId: track.getSettings().deviceId,
                            settings: track.getSettings()
                        })));
                        
                        permissionStream.getTracks().forEach(track => track.stop());
                    }
                    
                    // Re-enumerate with permissions
                    devices = await navigator.mediaDevices.enumerateDevices();
                    audioInputs = devices.filter(device => device.kind === 'audioinput');
                }
                
                availableDevices = audioInputs;
                console.log('üé§ Final available devices:', availableDevices);
                
                updateMicrophoneDropdown();
                
            } catch (error) {
                console.error('Error enumerating audio devices:', error);
                updateStatus(`Failed to access microphones: ${error.message}. Please check browser permissions.`, 'error');
                
                // Show basic troubleshooting info
                setTimeout(() => {
                    const troubleshoot = `
                    üé§ MICROPHONE TROUBLESHOOTING:
                    1. Check that your browser has microphone permissions
                    2. Make sure your external microphone is properly connected
                    3. Try refreshing the page and granting permissions again
                    4. Check if other apps are using the microphone
                    5. Try using Chrome/Edge instead of Safari if on Mac
                    `;
                    console.log(troubleshoot);
                }, 1000);
            }
        }
        
        function updateMicrophoneDropdown() {
            microphoneSelect.innerHTML = '';
            
            if (availableDevices.length === 0) {
                microphoneSelect.innerHTML = '<option value="">‚ùå No microphones found</option>';
                return;
            }
            
            // Add default option
            const defaultOption = document.createElement('option');
            defaultOption.value = '';
            defaultOption.textContent = 'üé§ Select a microphone...';
            microphoneSelect.appendChild(defaultOption);
            
            // Add each available microphone
            availableDevices.forEach((device, index) => {
                const option = document.createElement('option');
                option.value = device.deviceId;
                
                // Create a descriptive label
                let label = device.label || `Microphone ${index + 1}`;
                
                // Add device type hints based on label
                if (label.toLowerCase().includes('built-in') || label.toLowerCase().includes('internal')) {
                    label = `üíª ${label} (Built-in)`;
                } else if (label.toLowerCase().includes('usb')) {
                    label = `üîå ${label} (USB)`;
                } else if (label.toLowerCase().includes('bluetooth') || label.toLowerCase().includes('airpods') || label.toLowerCase().includes('headset')) {
                    label = `üì± ${label} (Bluetooth/Phone)`;
                } else {
                    label = `üé§ ${label}`;
                }
                
                option.textContent = label;
                microphoneSelect.appendChild(option);
                
                // Auto-select first non-phone/bluetooth device
                if (!selectedDeviceId && !label.includes('Phone') && !label.includes('Bluetooth') && !label.includes('AirPods')) {
                    selectedDeviceId = device.deviceId;
                    option.selected = true;
                }
            });
            
            updateStatus(`Found ${availableDevices.length} microphone(s). Please select your preferred microphone.`, 'info');
        }
        
        function onMicrophoneChange() {
            selectedDeviceId = microphoneSelect.value;
            const selectedDevice = availableDevices.find(d => d.deviceId === selectedDeviceId);
            
            if (selectedDevice) {
                updateStatus(`Selected: ${selectedDevice.label || 'Microphone'}`, 'info');
            } else {
                updateStatus('Please select a microphone before recording.', 'warning');
            }
        }
        
        function startAudioLevelMonitoring(stream) {
            try {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                
                analyser.fftSize = 256;
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                microphone.connect(analyser);
                levelMonitoringActive = true;
                
                document.getElementById('audioLevelContainer').style.display = 'block';
                
                function updateLevel() {
                    if (!levelMonitoringActive) return;
                    
                    analyser.getByteFrequencyData(dataArray);
                    
                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    const percentage = Math.round((average / 255) * 100);
                    
                    // Update visual indicator
                    const levelBar = document.getElementById('audioLevelBar');
                    const levelText = document.getElementById('audioLevelText');
                    
                    levelBar.style.width = `${percentage}%`;
                    levelText.textContent = `${percentage}%`;
                    
                    // Color coding based on level
                    if (percentage < 10) {
                        levelBar.style.background = '#e74c3c'; // Red - too quiet
                    } else if (percentage < 30) {
                        levelBar.style.background = '#f39c12'; // Orange - low
                    } else if (percentage < 80) {
                        levelBar.style.background = '#27ae60'; // Green - good
                    } else {
                        levelBar.style.background = '#e74c3c'; // Red - too loud
                    }
                    
                    requestAnimationFrame(updateLevel);
                }
                
                updateLevel();
                
            } catch (error) {
                console.error('Error starting audio level monitoring:', error);
            }
        }
        
        function stopAudioLevelMonitoring() {
            levelMonitoringActive = false;
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            document.getElementById('audioLevelContainer').style.display = 'none';
            document.getElementById('audioLevelBar').style.width = '0%';
            document.getElementById('audioLevelText').textContent = '0%';
        }
        
        // Test microphone function
        async function testSelectedMicrophone() {
            if (!selectedDeviceId) {
                updateStatus('Please select a microphone first!', 'error');
                return;
            }
            
            const selectedDevice = availableDevices.find(d => d.deviceId === selectedDeviceId);
            updateStatus(`Testing microphone: ${selectedDevice?.label || 'Selected microphone'}...`, 'warning');
            
            console.log('üß™ Testing microphone:', selectedDevice);
            
            let testStream = null;
            
            try {
                // Test multiple constraint configurations
                const testConstraints = [
                    // Test 1: Basic access
                    { deviceId: { ideal: selectedDeviceId } },
                    // Test 2: With sample rate
                    { deviceId: { ideal: selectedDeviceId }, sampleRate: { ideal: 16000 } },
                    // Test 3: With processing
                    { 
                        deviceId: { ideal: selectedDeviceId }, 
                        echoCancellation: true, 
                        noiseSuppression: true 
                    },
                    // Test 4: Exact device ID
                    { deviceId: { exact: selectedDeviceId } }
                ];
                
                for (let i = 0; i < testConstraints.length; i++) {
                    const constraints = testConstraints[i];
                    
                    try {
                        console.log(`üß™ Test ${i + 1} - Constraints:`, constraints);
                        
                        testStream = await navigator.mediaDevices.getUserMedia({ audio: constraints });
                        
                        const track = testStream.getAudioTracks()[0];
                        const settings = track.getSettings();
                        const capabilities = track.getCapabilities ? track.getCapabilities() : {};
                        
                        console.log(`üß™ Test ${i + 1} - SUCCESS`);
                        console.log('üß™ Track settings:', settings);
                        console.log('üß™ Track capabilities:', capabilities);
                        console.log('üß™ Track label:', track.label);
                        console.log('üß™ Track kind:', track.kind);
                        console.log('üß™ Track enabled:', track.enabled);
                        console.log('üß™ Track muted:', track.muted);
                        console.log('üß™ Track readyState:', track.readyState);
                        
                        // Quick audio level test
                        const testAudioContext = new (window.AudioContext || window.webkitAudioContext)();
                        const testAnalyser = testAudioContext.createAnalyser();
                        const testMicrophone = testAudioContext.createMediaStreamSource(testStream);
                        testMicrophone.connect(testAnalyser);
                        
                        testAnalyser.fftSize = 256;
                        const testDataArray = new Uint8Array(testAnalyser.frequencyBinCount);
                        
                        setTimeout(() => {
                            testAnalyser.getByteFrequencyData(testDataArray);
                            let sum = 0;
                            for (let j = 0; j < testDataArray.length; j++) {
                                sum += testDataArray[j];
                            }
                            const average = sum / testDataArray.length;
                            const percentage = Math.round((average / 255) * 100);
                            
                            console.log(`üß™ Audio level test: ${percentage}% (${average}/255)`);
                            console.log('üß™ Raw frequency data sample:', testDataArray.slice(0, 10));
                            
                            testAudioContext.close();
                            
                            if (percentage > 0) {
                                updateStatus(`‚úÖ Microphone test PASSED! Audio detected (${percentage}% level). Constraint set ${i + 1} works.`, 'info');
                            } else {
                                updateStatus(`‚ö†Ô∏è Microphone accessible but no audio detected. Speak into the microphone or check volume levels.`, 'warning');
                            }
                        }, 2000);
                        
                        // Stop test stream
                        setTimeout(() => {
                            testStream.getTracks().forEach(track => track.stop());
                        }, 3000);
                        
                        return; // Exit on first successful test
                        
                    } catch (testError) {
                        console.log(`üß™ Test ${i + 1} - FAILED:`, testError.message);
                        
                        if (testStream) {
                            testStream.getTracks().forEach(track => track.stop());
                            testStream = null;
                        }
                    }
                }
                
                // If we get here, all tests failed
                throw new Error('All microphone test configurations failed');
                
            } catch (error) {
                console.error('üß™ Microphone test failed:', error);
                updateStatus(`‚ùå Microphone test FAILED: ${error.message}`, 'error');
                
                // Cleanup
                if (testStream) {
                    testStream.getTracks().forEach(track => track.stop());
                }
            }
        }
        
        function updateStatus(message, type = 'info') {
            status.textContent = message;
            status.className = `status ${type}`;
        }
        
        function updateTimer() {
            if (!startTime) return;
            const elapsed = Date.now() - startTime;
            const minutes = Math.floor(elapsed / 60000);
            const seconds = Math.floor((elapsed % 60000) / 1000);
            timer.textContent = `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
        }
        
        async function startRecording() {
            try {
                // Check if microphone is selected
                if (!selectedDeviceId) {
                    updateStatus('Please select a microphone first!', 'error');
                    return;
                }
                
                // Request microphone access with selected device
                const selectedDevice = availableDevices.find(d => d.deviceId === selectedDeviceId);
                updateStatus(`Starting recording with: ${selectedDevice?.label || 'Selected microphone'}...`, 'warning');
                
                console.log('üé§ Selected device:', selectedDevice);
                console.log('üé§ Device ID:', selectedDeviceId);
                
                // Try multiple constraint configurations optimized for speech recognition
                const constraintOptions = [
                    // Option 1: High-quality microphone optimized for Gladia STT
                    {
                        deviceId: { exact: selectedDeviceId },
                        sampleRate: { ideal: 48000, min: 44100 }, // Higher sample rate for clarity
                        channelCount: 1,
                        echoCancellation: false,    // Disable - causes audio distortion for STT
                        noiseSuppression: false,    // Disable - STT works better with natural audio
                        autoGainControl: false,     // Disable - maintains consistent volume levels
                        latency: { ideal: 0.01 },   // Low latency for real-time feel
                        volume: { ideal: 1.0 }      // Full volume capture
                    },
                    // Option 2: Medium quality fallback (44.1kHz)
                    {
                        deviceId: { ideal: selectedDeviceId },
                        sampleRate: { ideal: 44100 },
                        channelCount: 1,
                        echoCancellation: false,
                        noiseSuppression: false,
                        autoGainControl: true       // Enable AGC as fallback only
                    },
                    // Option 3: Standard STT quality (16kHz, no processing)
                    {
                        deviceId: { ideal: selectedDeviceId },
                        sampleRate: { ideal: 16000 },
                        channelCount: 1,
                        echoCancellation: false,
                        noiseSuppression: false
                    },
                    // Option 4: Compatibility mode (original constraints)
                    {
                        deviceId: { ideal: selectedDeviceId },
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true
                    },
                    // Option 5: Minimal constraints (last resort)
                    {
                        deviceId: { ideal: selectedDeviceId }
                    }
                ];
                
                stream = null; // Use global stream variable
                let usedConstraints = null;
                
                // Try each constraint configuration until one works
                for (let i = 0; i < constraintOptions.length; i++) {
                    try {
                        console.log(`üé§ Trying constraint option ${i + 1}:`, constraintOptions[i]);
                        
                        stream = await navigator.mediaDevices.getUserMedia({
                            audio: constraintOptions[i]
                        });
                        
                        usedConstraints = constraintOptions[i];
                        const qualityLevel = [
                            'High-Quality (48kHz, no processing)',
                            'Medium-Quality (44.1kHz)',  
                            'Standard STT (16kHz)',
                            'Compatibility Mode',
                            'Minimal Constraints'
                        ][i] || 'Unknown';
                        console.log(`üé§ Success with option ${i + 1}: ${qualityLevel}`);
                        updateStatus(`üé§ Using ${qualityLevel} - optimized for speech recognition`, 'info');
                        break;
                        
                    } catch (constraintError) {
                        console.warn(`üé§ Constraint option ${i + 1} failed:`, constraintError.message);
                        
                        if (i === constraintOptions.length - 1) {
                            // If all constraints fail, throw the last error
                            throw constraintError;
                        }
                    }
                }
                
                if (!stream) {
                    throw new Error('Could not access microphone with any constraint configuration');
                }
                
                // Log the actual stream settings
                const audioTracks = stream.getAudioTracks();
                if (audioTracks.length > 0) {
                    const track = audioTracks[0];
                    console.log('üé§ Actual stream settings:', track.getSettings());
                    console.log('üé§ Stream constraints used:', usedConstraints);
                    
                    updateStatus(`üé§ Recording started with ${track.label || 'microphone'} (${JSON.stringify(track.getSettings())})`, 'info');
                }
                
                // Start audio level monitoring
                startAudioLevelMonitoring(stream);
                
                // Test microphone functionality
                const testRecordingCapability = () => {
                    const audioTracks = stream.getAudioTracks();
                    if (audioTracks.length > 0) {
                        const track = audioTracks[0];
                        const capabilities = track.getCapabilities ? track.getCapabilities() : {};
                        console.log('üé§ Microphone capabilities:', capabilities);
                        
                        // Check if the track is actually getting audio data
                        setTimeout(() => {
                            const settings = track.getSettings();
                            console.log('üé§ Current microphone settings:', settings);
                            
                            if (settings.deviceId !== selectedDeviceId) {
                                console.warn('üé§ Warning: Using different device than selected!');
                                console.warn('üé§ Selected:', selectedDeviceId);
                                console.warn('üé§ Actual:', settings.deviceId);
                            }
                        }, 1000);
                    }
                };
                
                testRecordingCapability();
                
                recordedChunks = [];
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        recordedChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    recordedBlob = new Blob(recordedChunks, { type: 'audio/webm' });
                    clearInterval(timerInterval);
                    
                    // Create local audio player
                    const audioURL = URL.createObjectURL(recordedBlob);
                    const audioPlayer = document.getElementById('audioPlayer');
                    audioPlayer.innerHTML = `
                        <h4>üéµ Recorded Audio (${Math.round(recordedBlob.size / 1024)}KB)</h4>
                        <audio controls class="audio-player">
                            <source src="${audioURL}" type="audio/webm">
                            Your browser does not support the audio element.
                        </audio>
                    `;
                    
                    updateStatus('Recording completed! Uploading to PitchScoop automatically...', 'info');
                    
                    // Always auto-upload - no manual upload needed
                    await uploadRecording();
                };
                
                // Start recording
                mediaRecorder.start(100); // Record in 100ms chunks
                startTime = Date.now();
                timerInterval = setInterval(updateTimer, 100);
                
                startBtn.disabled = true;
                startBtn.className = 'record-btn recording';
                stopBtn.disabled = false;
                
                updateStatus('üî¥ Recording... Speak into your microphone!', 'info');
                
            } catch (error) {
                updateStatus(`Failed to start recording: ${error.message}`, 'error');
                console.error('Recording error:', error);
            }
        }
        
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                
                // Safely stop stream tracks
                if (stream && stream.getTracks) {
                    stream.getTracks().forEach(track => track.stop());
                }
                
                // Stop audio level monitoring
                stopAudioLevelMonitoring();
                
                startBtn.disabled = false;
                startBtn.className = 'record-btn';
                stopBtn.disabled = true;
                
                results.style.display = 'block';
            }
        }
        
        async function uploadRecording() {
            if (!recordedBlob) {
                updateStatus('No recording to upload!', 'error');
                return;
            }
            
            try {
                updateStatus('Uploading to PitchScoop...', 'warning');
                
                const teamName = document.getElementById('teamName').value || 'Test Team';
                const pitchTitle = document.getElementById('pitchTitle').value || 'Browser Recording Test';
                
                // Always create a new event for testing
                updateStatus('Creating new event...', 'warning');
                const eventResponse = await fetch(`${API_BASE_URL}/mcp/execute`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        tool: 'events.create_event',
                        arguments: {
                            event_type: 'individual_practice',
                            event_name: 'Browser Recording Test Event',
                            description: 'Test event created from browser recording',
                            max_participants: 1,
                            duration_minutes: 10
                        }
                    })
                });
                
                const eventData = await eventResponse.json();
                if (eventData.error) {
                    throw new Error(`Event creation failed: ${eventData.error}`);
                }
                
                const eventId = eventData.event_id;
                updateStatus(`Event created: ${eventId}`, 'info');
                
                // Step 2: Start recording session
                updateStatus('Starting recording session...', 'warning');
                const sessionResponse = await fetch(`${API_BASE_URL}/mcp/execute`, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        tool: 'pitches.start_recording',
                        arguments: {
                            event_id: eventId,
                            team_name: teamName,
                            pitch_title: pitchTitle
                        }
                    })
                });
                
                const sessionData = await sessionResponse.json();
                if (sessionData.error) {
                    throw new Error(`Session creation failed: ${sessionData.error}`);
                }
                
                const sessionId = sessionData.session_id;
                updateStatus(`Recording session created: ${sessionId}`, 'info');
                
                // Step 3: Send raw WebM to backend for proper conversion
                updateStatus('Sending raw WebM audio to backend for optimal processing...', 'warning');
                
                // Send the original WebM blob directly (bypass problematic JS conversion)
                const webmReader = new FileReader();
                webmReader.onload = async () => {
                    try {
                        const base64WebM = webmReader.result.split(',')[1]; // Remove data prefix
                        
                        const stopResponse = await fetch(`${API_BASE_URL}/mcp/execute`, {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify({
                                tool: 'pitches.stop_recording',
                                arguments: {
                                    session_id: sessionId,
                                    audio_data_base64: base64WebM,
                                    audio_format: 'webm'  // Tell backend this is WebM
                                }
                            })
                        });
                        
                        const stopData = await stopResponse.json();
                        if (stopData.error) {
                            throw new Error(`Upload failed: ${stopData.error}`);
                        }
                    
                    const stopData = await stopResponse.json();
                    if (stopData.error) {
                        throw new Error(`Upload failed: ${stopData.error}`);
                    }
                    
                    // Display results
                    const sessionInfo = document.getElementById('sessionInfo');
                    
                    // Check for transcript
                    let transcriptHtml = '';
                    const transcript = stopData.transcript;
                    if (transcript) {
                        const totalText = transcript.total_text || '';
                        const segmentCount = transcript.segments_count || 0;
                        const segments = transcript.segments || [];
                        
                        if (totalText.trim()) {
                            // Calculate average confidence
                            let avgConfidence = 0;
                            let confidenceCount = 0;
                            let qualityWarning = '';
                            
                            segments.forEach(seg => {
                                if (seg.confidence !== undefined) {
                                    avgConfidence += seg.confidence;
                                    confidenceCount++;
                                }
                            });
                            
                            if (confidenceCount > 0) {
                                avgConfidence = avgConfidence / confidenceCount;
                                
                                if (avgConfidence < 0.3) {
                                    qualityWarning = '<div style="background: #f8d7da; color: #721c24; padding: 10px; border-radius: 5px; margin: 10px 0;">‚ö†Ô∏è <strong>Very Low Quality:</strong> Transcript may be inaccurate. Try speaking louder and closer to the microphone.</div>';
                                } else if (avgConfidence < 0.6) {
                                    qualityWarning = '<div style="background: #fff3cd; color: #856404; padding: 10px; border-radius: 5px; margin: 10px 0;">‚ö†Ô∏è <strong>Low Quality:</strong> Consider improving audio quality for better accuracy.</div>';
                                } else {
                                    qualityWarning = '<div style="background: #d4edda; color: #155724; padding: 10px; border-radius: 5px; margin: 10px 0;">‚úÖ <strong>Good Quality:</strong> Transcript should be accurate.</div>';
                                }
                            }
                            
                            let segmentDetails = '';
                            if (segments.length > 0) {
                                segmentDetails = '<h5>Segment Details:</h5>';
                                segments.forEach((seg, i) => {
                                    const conf = seg.confidence !== undefined ? (seg.confidence * 100).toFixed(0) + '%' : 'N/A';
                                    const confColor = seg.confidence < 0.3 ? '#e74c3c' : seg.confidence < 0.6 ? '#f39c12' : '#27ae60';
                                    segmentDetails += `<div style="margin: 5px 0; padding: 8px; background: #f8f9fa; border-radius: 3px;"><strong>"${seg.text}"</strong> <span style="color: ${confColor}; font-weight: bold;">(${conf})</span></div>`;
                                });
                            }
                            
                            transcriptHtml = `
                                <h4>üìù Transcript</h4>
                                <div style="background: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;">
                                    <strong>"${totalText}"</strong>
                                </div>
                                ${qualityWarning}
                                <p><small>Segments: ${segmentCount} | Avg. Confidence: ${confidenceCount > 0 ? (avgConfidence * 100).toFixed(0) + '%' : 'N/A'}</small></p>
                                ${segmentDetails}
                            `;
                        } else if (segmentCount > 0) {
                            transcriptHtml = `
                                <h4>üìù Transcript</h4>
                                <p><em>Processing completed but no text detected (${segmentCount} segments processed)</em></p>
                            `;
                        } else {
                            transcriptHtml = `
                                <h4>üìù Transcript</h4>
                                <p><em>No transcript segments detected - this may happen with synthetic audio or background noise</em></p>
                            `;
                        }
                    }
                    
                    // Debug: Log the full response for analysis
                    console.log('üîç Full stopData response:', stopData);
                    console.log('üîç Transcript object:', transcript);
                    if (transcript && transcript.segments) {
                        console.log('üîç Individual segments:', transcript.segments);
                    }
                    
                    sessionInfo.innerHTML = `
                        <h4>‚úÖ Upload Successful!</h4>
                        <p><strong>Session ID:</strong> ${sessionId}</p>
                        <p><strong>Event ID:</strong> ${eventId}</p>
                        <p><strong>Team:</strong> ${teamName}</p>
                        <p><strong>Title:</strong> ${pitchTitle}</p>
                        <p><strong>Status:</strong> ${stopData.status}</p>
                        <p><strong>File Size:</strong> ${Math.round(wavBlob.size / 1024)}KB (WAV format)</p>
                        <p><strong>Processing Method:</strong> ${transcript && transcript.audio_intelligence && Object.keys(transcript.audio_intelligence).length > 0 ? 'Batch API (Audio Intelligence)' : 'WebSocket API (Basic)'}</p>
                        ${transcriptHtml}
                    `;
                    
                    updateStatus('üéâ Recording successfully uploaded to MinIO!', 'info');
                };
                
                reader.readAsDataURL(wavBlob);
                
            } catch (error) {
                updateStatus(`Upload failed: ${error.message}`, 'error');
                console.error('Upload error:', error);
            }
        }
        
        // Convert AudioBuffer to WAV Blob
        function audioBufferToWav(buffer) {
            const length = buffer.length;
            const sampleRate = buffer.sampleRate;
            const arrayBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(arrayBuffer);
            const channelData = buffer.getChannelData(0);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, channelData[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
            
            return new Blob([arrayBuffer], { type: 'audio/wav' });
        }
        
        // Scoring functionality
        let sessions = [];
        
        async function loadSessions() {
            try {
                updateStatus('Loading sessions...', 'warning');
                const response = await fetch('/api/sessions');
                const data = await response.json();
                
                if (data.error) {
                    throw new Error(data.error);
                }
                
                sessions = data.sessions || [];
                renderSessions();
                updateStatus('Sessions loaded successfully!', 'info');
            } catch (error) {
                console.error('Error loading sessions:', error);
                document.getElementById('sessionsContainer').innerHTML = 
                    `<div class="status error">Error loading sessions: ${error.message}</div>`;
                updateStatus(`Error loading sessions: ${error.message}`, 'error');
            }
        }
        
        function renderSessions() {
            const container = document.getElementById('sessionsContainer');
            
            if (sessions.length === 0) {
                container.innerHTML = '<div class="status warning">No recording sessions found</div>';
                return;
            }
            
            const completedSessions = sessions.filter(s => s.status === 'completed');
            
            if (completedSessions.length === 0) {
                container.innerHTML = `
                    <div class="status warning">
                        No completed sessions found. Only completed sessions with transcripts can be scored.
                        <br><br>
                        Found ${sessions.length} sessions total, but they are not completed yet.
                    </div>
                `;
                return;
            }
            
            container.innerHTML = `
                <p><strong>${completedSessions.length}</strong> completed sessions ready for scoring:</p>
                <div class="session-list">
                    ${completedSessions.map(session => `
                        <div class="session-item">
                            <div class="session-info">
                                <h3>${session.team_name} - ${session.pitch_title}</h3>
                                <p><strong>Session ID:</strong> ${session.session_id}</p>
                                <p><strong>Created:</strong> ${new Date(session.created_at).toLocaleString()}</p>
                                <p><strong>Duration:</strong> ${session.duration_seconds ? session.duration_seconds.toFixed(1) + 's' : 'N/A'}</p>
                                <span class="status-badge status-${session.status}">${session.status}</span>
                                ${session.has_audio ? '<span class="status-badge status-completed">Audio Available</span>' : ''}
                            </div>
                            <div class="actions">
                                <button onclick="getAudioIntelligence('${session.session_id}')" class="scoring-btn">
                                    üéµ Audio Intelligence
                                </button>
                                <button onclick="getScoring('${session.session_id}')" class="scoring-btn primary">
                                    üéØ Get Score
                                </button>
                            </div>
                        </div>
                    `).join('')}
                </div>
            `;
        }
        
        async function getScoring(sessionId) {
            try {
                updateStatus('Analyzing presentation delivery...', 'warning');
                
                // Show scoring results section
                document.getElementById('scoringContent').innerHTML = '<div class="status info">Analyzing presentation delivery...</div>';
                document.getElementById('scoringResults').style.display = 'block';
                document.getElementById('scoringResults').scrollIntoView({behavior: 'smooth'});
                
                // Get session details first to find the event_id
                let eventId = 'default';
                
                try {
                    const sessionResponse = await fetch('/mcp/execute', {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                        },
                        body: JSON.stringify({
                            tool: 'pitches.get_session',
                            arguments: { session_id: sessionId }
                        })
                    });
                    
                    const sessionData = await sessionResponse.json();
                    if (sessionData && sessionData.event_id) {
                        eventId = sessionData.event_id;
                    }
                } catch (e) {
                    console.warn('Could not get event_id, using default:', e);
                }
                
                // Now get the scoring
                const response = await fetch(`/api/sessions/${sessionId}/scoring?event_id=${eventId}`);
                const data = await response.json();
                
                if (data.error) {
                    throw new Error(data.error);
                }
                
                renderScoringResults(data);
                updateStatus('Presentation analysis complete!', 'info');
            } catch (error) {
                console.error('Error getting scoring:', error);
                document.getElementById('scoringContent').innerHTML = 
                    `<div class="status error">Error getting scoring: ${error.message}</div>`;
                updateStatus(`Error getting scoring: ${error.message}`, 'error');
            }
        }
        
        async function getAudioIntelligence(sessionId) {
            try {
                updateStatus('Fetching audio intelligence...', 'warning');
                
                document.getElementById('scoringContent').innerHTML = '<div class="status info">Fetching audio intelligence...</div>';
                document.getElementById('scoringResults').style.display = 'block';
                document.getElementById('scoringResults').scrollIntoView({behavior: 'smooth'});
                
                const response = await fetch(`/api/sessions/${sessionId}/audio-intelligence`);
                const data = await response.json();
                
                renderAudioIntelligence(data);
                updateStatus('Audio intelligence fetch complete!', 'info');
            } catch (error) {
                console.error('Error getting audio intelligence:', error);
                document.getElementById('scoringContent').innerHTML = 
                    `<div class="status error">Error getting audio intelligence: ${error.message}</div>`;
                updateStatus(`Error getting audio intelligence: ${error.message}`, 'error');
            }
        }
        
        function renderScoringResults(data) {
            const content = document.getElementById('scoringContent');
            
            if (data.error) {
                content.innerHTML = `<div class="status error">${data.error}</div>`;
                return;
            }
            
            const scoring = data.combined_scoring || {};
            const transcriptAnalysis = data.transcript_analysis || {};
            const audioIntelligence = data.audio_intelligence || {};
            const coachingInsights = data.coaching_insights || [];
            
            content.innerHTML = `
                <div class="score-card">
                    <div class="score-display">${scoring.overall_presentation_score || 'N/A'}/25</div>
                    <div class="grade-display">Grade: ${scoring.grade || 'N/A'}</div>
                    <p>Overall Presentation Delivery Score</p>
                </div>
                
                <div class="metrics-grid">
                    <div class="metric-card">
                        <h3>üìù Transcript Analysis</h3>
                        <p><strong>Score:</strong> ${scoring.transcript_score || 'N/A'}</p>
                        <p><strong>Word Count:</strong> ${transcriptAnalysis.transcript_metrics?.word_count || 'N/A'}</p>
                        <p><strong>Estimated Duration:</strong> ${transcriptAnalysis.transcript_metrics?.estimated_duration_minutes || 'N/A'} min</p>
                        <p><strong>Structure Score:</strong> ${transcriptAnalysis.scoring?.structure_score || 'N/A'}</p>
                        <p><strong>Clarity Score:</strong> ${transcriptAnalysis.scoring?.clarity_score || 'N/A'}</p>
                    </div>
                    
                    <div class="metric-card">
                        <h3>üéµ Audio Intelligence</h3>
                        ${audioIntelligence.available === false ? 
                            `<p>Audio intelligence data not available for this session.</p>
                             <p><em>Reason:</em> ${audioIntelligence.reason || 'Unknown'}</p>` :
                            `<p><strong>Audio Score:</strong> ${scoring.audio_score || 'N/A'}</p>
                             <p><strong>Available:</strong> ${audioIntelligence.available ? 'Yes' : 'No'}</p>`
                        }
                    </div>
                </div>
                
                ${coachingInsights.length > 0 ? `
                    <div class="coaching-insights">
                        <h3>üí° Coaching Insights</h3>
                        <ul>
                            ${coachingInsights.map(insight => `<li>${insight}</li>`).join('')}
                        </ul>
                    </div>
                ` : ''}
                
                <div class="analysis-metadata">
                    <h4>Analysis Details</h4>
                    <p><strong>Session:</strong> ${data.team_name} - ${data.pitch_title}</p>
                    <p><strong>Session ID:</strong> ${data.session_id}</p>
                    ${data._analysis_metadata ? `
                        <p><strong>Analysis Duration:</strong> ${data._analysis_metadata.analysis_duration_seconds}s</p>
                        <p><strong>Audio Integration:</strong> ${data._analysis_metadata.included_audio_intelligence ? 'Yes' : 'No'}</p>
                        <p><strong>Completed:</strong> ${new Date(data._analysis_metadata.completed_at).toLocaleString()}</p>
                    ` : ''}
                </div>
            `;
        }
        
        function renderAudioIntelligence(data) {
            const content = document.getElementById('scoringContent');
            
            if (data.error) {
                content.innerHTML = `
                    <div class="status error">
                        <strong>Audio Intelligence Error:</strong> ${data.error}<br>
                        <em>Error Type:</em> ${data.error_type || 'unknown'}<br><br>
                        This is expected if the session doesn't have full Gladia Audio Intelligence data.
                        Most test sessions won't have this data unless recorded with specific AI features enabled.
                    </div>
                `;
                return;
            }
            
            content.innerHTML = `
                <div class="score-card">
                    <div class="score-display">üéµ</div>
                    <div class="grade-display">Audio Intelligence</div>
                    <p>Speech Analysis Results</p>
                </div>
                
                <div class="metrics-grid">
                    <div class="metric-card">
                        <h3>Raw Response</h3>
                        <pre style="background: #f5f5f5; padding: 10px; border-radius: 4px; overflow-x: auto; font-size: 0.8em;">${JSON.stringify(data, null, 2)}</pre>
                    </div>
                </div>
            `;
        }
        
        function hideScoringResults() {
            document.getElementById('scoringResults').style.display = 'none';
            updateStatus('Scoring results closed', 'info');
        }
        
        
        // Event listeners
        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        microphoneSelect.addEventListener('change', onMicrophoneChange);
        refreshMicsBtn.addEventListener('click', enumerateAudioDevices);
        testMicBtn.addEventListener('click', testSelectedMicrophone);
        
        // Initialize on page load
        window.addEventListener('load', async () => {
            // Check if browser supports recording
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                updateStatus('Your browser does not support audio recording!', 'error');
                startBtn.disabled = true;
                return;
            }
            
            // Enumerate available microphones
            await enumerateAudioDevices();
        });
    </script>
</body>
</html>